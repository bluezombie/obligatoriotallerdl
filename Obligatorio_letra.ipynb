{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZzGt0PbUIGG"
   },
   "source": [
    "# Obligatorio - Taller de Deep Learning\n",
    "\n",
    "**Fecha de entrega:** 10/12/2024  \n",
    "**Puntaje máximo:** 50 puntos  \n",
    "\n",
    "## Obligatorio\n",
    "\n",
    "El objetivo de este obligatorio es evaluar su conocimiento en Deep Learning mediante la implementación completa de un modelo de segmentación de imágenes basado en el paper [**\"U-Net: Convolutional Networks for Biomedical Image Segmentation\"**](https://arxiv.org/pdf/1505.04597). Toda la implementación debe realizarse desde cero utilizando PyTorch, y los estudiantes tendrán la libertad de ajustar ciertos hiperparámetros y configuraciones mientras mantengan la esencia del paper original.\n",
    "\n",
    "### **Competencia en Kaggle**\n",
    "\n",
    "Además, como parte de este obligatorio, participarán en una competencia privada en Kaggle donde se les proporcionará un dataset de test oculto (sin target). Deberán subir sus predicciones a Kaggle y se evaluarán en función de la métrica **Dice Coefficient (Coeficiente de Dice)**. Esta competencia les permitirá comparar sus resultados con los de sus compañeros en un entorno real de evaluación.\n",
    "\n",
    "### **Qué es el Dice Coefficient?**\n",
    "El **Dice Coefficient**, también conocido como F1-score para segmentación, es una métrica utilizada para evaluar la similitud entre la predicción y la verdad del terreno en tareas de segmentación. Se define de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\\text{Dice} = \\frac{2 \\cdot |A \\cap B|}{|A| + |B|}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- \\(A\\) es el conjunto de píxeles predichos como pertenecientes a la clase positiva.\n",
    "- \\(B\\) es el conjunto de píxeles verdaderos pertenecientes a la clase positiva.\n",
    "- \\(|A \\cap B|\\) es la intersección de \\(A\\) y \\(B\\), es decir, los píxeles correctamente predichos como positivos.\n",
    "\n",
    "Un valor de Dice de **1** indica una predicción perfecta, mientras que un valor de **0** indica que no hay coincidencia entre la predicción y el valor verdadero. Durante la competencia de Kaggle, deberán obtener un puntaje de al menos **0.7** en la métrica Dice para considerarse aprobados.\n",
    "\n",
    "### **Criterios a Evaluar**\n",
    "\n",
    "1. **Implementación Correcta del Modelo U-Net (20 puntos):**\n",
    "   - Construcción de la arquitectura U-Net siguiendo la estructura descrita en el paper, permitiendo ajustes como el número de filtros, funciones de activación y métodos de inicialización de pesos.\n",
    "   - Se aceptan mejoras como el uso de técnicas adicionales como batch normalization, otras funciones de activación, etc.\n",
    "\n",
    "2. **Entrenamiento del Modelo (10 puntos):**\n",
    "   - Configuración adecuada del ciclo de entrenamiento, incluyendo la elección de la función de pérdida y del optimizador (Adam, SGD, etc.).\n",
    "   - Uso de técnicas de regularización para mejorar la generalización del modelo, como el dropout, normalización de batch y data augmentation.\n",
    "   - Gráficas y análisis de la evolución del entrenamiento, mostrando las curvas de pérdida y métricas relevantes tanto en el conjunto de entrenamiento como en el de validación.\n",
    "\n",
    "3. **Evaluación de Resultados (10 puntos):**\n",
    "   - Evaluación exhaustiva del modelo utilizando métricas de segmentación como **Dice Coefficient**.\n",
    "   - Análisis detallado de los resultados, incluyendo un análisis de errores para identificar y discutir casos difíciles.\n",
    "   - Visualización de ejemplos representativos de segmentaciones correctas e incorrectas, comparando con las etiquetas manuales proporcionadas en el dataset.\n",
    "\n",
    "4. **Participación y Resultados en la Competencia Kaggle (5 puntos):**\n",
    "   - Participación activa en la competencia de Kaggle, con al menos una (1) subida de predicción.\n",
    "   - Puntaje obtenido en la tabla de posiciones de Kaggle, evaluado en base al **Dice Coefficient** en el conjunto de test oculto. Es necesario obtener al menos un valor de **0.7** para esta métrica.\n",
    "\n",
    "   Nota: El **Dice Coefficient** es la métrica utilizada para evaluar la precisión de los modelos de segmentación de imágenes en esta competencia. Un valor de Dice superior a 0.7 es requerido para aprobar esta tarea.\n",
    "\n",
    "### **Run-Length Encoding (RLE)**\n",
    "\n",
    "Dado que no se suben las imágenes segmentadas directamente a Kaggle, se requiere usar **Run-Length Encoding (RLE)** para comprimir las máscaras de predicción en una cadena de texto que será evaluada. El **RLE** es una técnica de compresión donde se representan secuencias consecutivas de píxeles en formato `start length`, indicando la posición de inicio y la longitud de cada secuencia de píxeles positivos.\n",
    "\n",
    "Para calcular el **RLE**, se sigue el siguiente proceso:\n",
    "\n",
    "1. Se aplanan las máscaras predichas en un solo vector\n",
    "2. Se identifican los píxeles con valor positivo (1) y se calculan las secuencias consecutivas.\n",
    "3. Se registra la posición de inicio de cada secuencia y su longitud en formato `start length`.\n",
    "\n",
    "Este formato comprimido se sube a Kaggle en lugar de las imágenes segmentadas.\n",
    "\n",
    "#### **Ejemplo de RLE**\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "def rle_encode(mask):\n",
    "    pixels = np.array(mask).flatten(order='F')  # Aplanar la máscara en orden Fortran\n",
    "    pixels = np.concatenate([[0], pixels, [0]])  # Añadir ceros al principio y final\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1  # Encontrar transiciones\n",
    "    runs[1::2] = runs[1::2] - runs[::2]  # Calcular longitudes\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "mask = np.array([[0, 0, 1, 0, 0],\n",
    "                 [0, 1, 1, 1, 0],\n",
    "                 [1, 1, 1, 0, 0],\n",
    "                 [0, 0, 0, 1, 1]])\n",
    "\n",
    "print(rle_encode(mask))\n",
    "```\n",
    "\n",
    "> **Salida:** 3 1 6 2 9 3 14 1 16 1 20 1\n",
    "\n",
    "\n",
    "### **Sobre el Dataset**\n",
    "\n",
    "El dataset proporcionado para esta tarea incluirá imágenes y máscaras para la segmentación de un conjunto específico de clases. El conjunto de entrenamiento estará disponible para su uso durante todo el proceso de desarrollo y pruebas, mientras que el conjunto de validación se mantendrá oculto para la evaluación final en Kaggle.\n",
    "\n",
    "### **Instrucciones de Entrega**\n",
    "\n",
    "- Deberán entregar un Jupyter Notebook (.ipynb) que contenga todo el código y las explicaciones necesarias para ejecutar la implementación, el entrenamiento y la evaluación del modelo.\n",
    "- El notebook debe incluir secciones bien documentadas explicando las decisiones de diseño del modelo, los experimentos realizados, y los resultados obtenidos.\n",
    "- El código debe estar escrito de manera clara.\n",
    "- La entrega debe realizarse a través de la plataforma de gestión de ORT (gestion.ort.edu.uy) antes de la fecha límite.\n",
    "\n",
    "### **Materiales Adicionales**\n",
    "\n",
    "Para facilitar su trabajo, pueden consultar los siguientes recursos:\n",
    "\n",
    "- [U-Net: Convolutional Networks for Biomedical Image Segmentation (paper original)](https://arxiv.org/abs/1505.04597)\n",
    "- [Documentación de PyTorch](https://pytorch.org/docs/stable/index.html)\n",
    "- [Tutoriales y recursos adicionales en Kaggle](https://www.kaggle.com/)\n",
    "\n",
    "### **Competencia Kaggle**\n",
    "\n",
    "https://www.kaggle.com/t/9b4e546084034a59b182aac1ae892640"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bDg55HyUIGR"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EX1bBPyfUIGR"
   },
   "source": [
    "\n",
    "## Requisitos Universitarios\n",
    "\n",
    "Fecha de entrega: 10/12/2024 hasta las 21:00 horas en gestion.ort.edu.uy (max. 40Mb en formato zip)\n",
    "\n",
    "### Uso de material de apoyo y/o consulta\n",
    "\n",
    "Inteligencia Artificial Generativa:\n",
    "\n",
    "   - Seguir las pautas de los docentes: Se deben seguir las instrucciones específicas de los docentes sobre cómo utilizar la IA en cada curso.\n",
    "   - Citar correctamente las fuentes y usos de IA: Siempre que se utilice una herramienta de IA para generar contenido, se debe citar adecuadamente la fuente y la forma en que se utilizó.\n",
    "   - Verificar el contenido generado por la IA: No todo el contenido generado por la IA es correcto o preciso. Es esencial que los estudiantes verifiquen la información antes de usarla.\n",
    "   - Ser responsables con el uso de la IA: Conocer los riesgos y desafíos, como la creación de “alucinaciones”, los peligros para la privacidad, las cuestiones de propiedad intelectual, los sesgos inherentes y la producción de contenido falso.\n",
    "   - En caso de existir dudas sobre la autoría, plagio o uso no atribuido de IAG, el docente tendrá la opción de convocar al equipo de obligatorio a una defensa específica e individual sobre el tema.\n",
    "\n",
    "### Defensa\n",
    "\n",
    "Fecha de defensa: 11/12/2024\n",
    "\n",
    "La defensa es obligatoria y eliminatoria. El docente es quien definirá y comunicará la modalidad, y mecánica de defensa. La no presentación a la misma implica la pérdida de la totalidad de los puntos del Obligatorio.\n",
    "\n",
    "IMPORTANTE:\n",
    "\n",
    "   1) Inscribirse\n",
    "   2) Formar grupos de hasta 2 personas del mismo dictado\n",
    "   3) Subir el trabajo a Gestión antes de la hora indicada (ver hoja al final del documento: “RECORDATORIO”)\n",
    "\n",
    "Aquellos de ustedes que presenten alguna dificultad con su inscripción o tengan inconvenientes técnicos, por favor contactarse con el Coordinador de cursos o Coordinación adjunta antes de las 20:00h del día de la entrega, a través de los mails crosa@ort.edu.uy / posada_l@ort.edu.uy (matutino) / larrosa@ort.edu.uy (nocturno), o vía Ms Teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bH1rWpba_Go"
   },
   "source": [
    "# Preparación entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXb6EO3JVPsM",
    "outputId": "1b0e5d69-7985-4eae-f857-5241a5070a01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.12\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AtegMesabVSN",
    "outputId": "08d79584-d5a1-4ba6-a306-3bb054305f25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl.metadata (13 kB)\n",
      "Collecting numpy>=1.19.5 (from scikit-learn)\n",
      "  Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.2-cp310-cp310-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading numpy-2.1.3-cp310-cp310-macosx_14_0_arm64.whl (5.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading scipy-1.14.1-cp310-cp310-macosx_14_0_arm64.whl (23.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.1/23.1 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "Successfully installed joblib-1.4.2 numpy-2.1.3 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Collecting kaggle\n",
      "  Downloading kaggle-1.6.17.tar.gz (82 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages (from kaggle) (1.17.0)\n",
      "Collecting certifi>=2023.7.22 (from kaggle)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: python-dateutil in /opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages (from kaggle) (2.9.0.post0)\n",
      "Collecting requests (from kaggle)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm (from kaggle)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting python-slugify (from kaggle)\n",
      "  Downloading python_slugify-8.0.4-py2.py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting urllib3 (from kaggle)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting bleach (from kaggle)\n",
      "  Downloading bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting webencodings (from bleach->kaggle)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting text-unidecode>=1.3 (from python-slugify->kaggle)\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests->kaggle)\n",
      "  Downloading charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kaggle)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Downloading python_slugify-8.0.4-py2.py3-none-any.whl (10 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp310-cp310-macosx_11_0_arm64.whl (120 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kaggle: filename=kaggle-1.6.17-py3-none-any.whl size=105786 sha256=35e2042d81cd174fffad80c04f0be17762e7585544f7e2fc93710ad50e2c77fe\n",
      "  Stored in directory: /Users/gotero/Library/Caches/pip/wheels/9f/af/22/bf406f913dc7506a485e60dce8143741abd0a92a19337d83a3\n",
      "Successfully built kaggle\n",
      "Installing collected packages: webencodings, text-unidecode, urllib3, tqdm, python-slugify, idna, charset-normalizer, certifi, bleach, requests, kaggle\n",
      "Successfully installed bleach-6.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 idna-3.10 kaggle-1.6.17 python-slugify-8.0.4 requests-2.32.3 text-unidecode-1.3 tqdm-4.67.1 urllib3-2.2.3 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchinfo\n",
    "!pip install scikit-learn\n",
    "!pip install kaggle\n",
    "!pip install matplotlib\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X80xVHuDmHhI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: /root: Read-only file system\n",
      "mv: rename kaggle.json to /root/.config/kaggle/: No such file or directory\n",
      "chmod: /root/.config/kaggle/kaggle.json: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Definimos el entorno para interactar con Kaggle\n",
    "# Debemos subir el archivo kaggle.json previamente\n",
    "#!mkdir -p /root/.config/kaggle\n",
    "#!mv kaggle.json /root/.config/kaggle/\n",
    "#!chmod 600 /root/.config/kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "str expected, not int",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKAGGLE_CONFIG_DIR\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./.kaggle\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPYTORCH_ENABLE_MPS_FALLBACK\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/os.py:685\u001b[0m, in \u001b[0;36m_Environ.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__setitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value):\n\u001b[1;32m    684\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)\n\u001b[0;32m--> 685\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencodevalue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m     putenv(key, value)\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[key] \u001b[38;5;241m=\u001b[39m value\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/os.py:757\u001b[0m, in \u001b[0;36m_createenviron.<locals>.encode\u001b[0;34m(value)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode\u001b[39m(value):\n\u001b[1;32m    756\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 757\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr expected, not \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(value)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39mencode(encoding, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogateescape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: str expected, not int"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KAGGLE_CONFIG_DIR\"] = \"./.kaggle\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "ljwM0SF0bBat"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.utils import make_grid\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from torchvision.transforms import v2 as T\n",
    "from torchvision.io import read_image, ImageReadMode\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from utils import (\n",
    "    train,\n",
    "    train_unet,\n",
    "    model_calassification_report,\n",
    "    show_tensor_image,\n",
    "    show_tensor_images,\n",
    "    print_log,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZslx9wPbhBO",
    "outputId": "cd84e6c8-b1cf-4a29-fcc7-4856a4c99322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "Num Workers: 0\n"
     ]
    }
   ],
   "source": [
    "# definimos el dispositivo que vamos a usar\n",
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "\n",
    "#NUM_WORKERS = max(os.cpu_count() - 1, 1)\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "DEVICE = \"cpu\"\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Num Workers: {NUM_WORKERS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NfQXb6nkXvfj",
    "outputId": "e6a8fdb2-1750-4b65-e5bf-416be6294313"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: nvidia-smi\n"
     ]
    }
   ],
   "source": [
    "# De acuerdo a la documentación de Colab, obtenemos información de la GPU\n",
    "# en caso de contar con ella.\n",
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "h-_obzs1dt2W"
   },
   "outputs": [],
   "source": [
    "# Constantes\n",
    "\n",
    "SEED = 34\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9uIx_1A4Y3cP"
   },
   "source": [
    "# Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "AnmE9vXdY5O2"
   },
   "outputs": [],
   "source": [
    "class PeopleDataset(Dataset):\n",
    "    def __init__(self, data, masks=None, img_transforms=None, mask_transforms=None):\n",
    "      self.train_data = data\n",
    "      self.train_masks = masks\n",
    "      self.img_transforms = img_transforms\n",
    "      self.mask_transforms = mask_transforms\n",
    "\n",
    "      self.images = sorted(os.listdir(self.train_data))\n",
    "      self.masks = sorted(os.listdir(self.train_masks))\n",
    "\n",
    "      print(f\"Valor de la transformación pasada como parámetro: \",mask_transforms)\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "      if self.train_masks is not None:\n",
    "        assert len(self.images) == len(self.masks), 'incompatibilidad de imágenes y máscaras'\n",
    "      return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      # Obtenemos los paths de las imágenes\n",
    "      img_path = os.path.join(self.train_data, self.images[idx])\n",
    "      mask_path = os.path.join(self.train_masks, self.masks[idx])\n",
    "\n",
    "      # Abrimos las imágenes y máscara\n",
    "      # image = Image.open(img_path)\n",
    "      # mask = Image.open(mask_path)\n",
    "\n",
    "      image = read_image(img_path)\n",
    "      mask = read_image(mask_path)\n",
    "\n",
    "      # Verificamos si existen transformaciones, y en caso que sí\n",
    "      # las aplicamos\n",
    "      if self.img_transforms:\n",
    "        image = self.img_transforms(image)\n",
    "      if self.mask_transforms is not None:\n",
    "        mask = self.mask_transforms(mask)\n",
    "\n",
    "\n",
    "      img = image.to(DEVICE)\n",
    "      # Nos quedamos con una sola capa de la imagen, ya que todas son iguales\n",
    "      msk = mask[0].to(DEVICE)\n",
    "\n",
    "      return img, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZaHnkDKwjjES",
    "outputId": "01618f42-ac88-406b-b42b-6bc817a11682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading tdl-segmentacion.zip to /content\n",
      "100% 2.14G/2.14G [01:39<00:00, 23.5MB/s]\n",
      "100% 2.14G/2.14G [01:39<00:00, 23.0MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Descargamos el dataset\n",
    "!kaggle competitions download -c tdl-segmentacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "4UHevwfqn4KL"
   },
   "outputs": [],
   "source": [
    "# Descomprimimos el dataset\n",
    "!unzip -q tdl-segmentacion.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxwANDv0ZPYm",
    "outputId": "691c2d21-701d-45cf-9fae-63b84148f4ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor de la transformación pasada como parámetro:  Compose(    Resize(size=[224, 224], interpolation=InterpolationMode.BILINEAR, antialias=True))\n",
      "Valor de la transformación pasada como parámetro:  None\n"
     ]
    }
   ],
   "source": [
    "TRAIN_PATH = 'train/images/'\n",
    "TRAIN_MASK_PATH = 'train/masks/'\n",
    "TEST_PATH = 'test/images/'\n",
    "\n",
    "transform_data = T.Compose([\n",
    "   T.Resize((224, 224))])\n",
    "\n",
    "target_transform = T.Compose([\n",
    "    T.Resize((224, 224))])\n",
    "\n",
    "full_dataset = PeopleDataset(data=TRAIN_PATH, masks=TRAIN_MASK_PATH, img_transforms=transform_data, mask_transforms=target_transform)\n",
    "\n",
    "TRAIN_SIZE = int(len(full_dataset)*0.8)\n",
    "VAL_SIZE = len(full_dataset) - TRAIN_SIZE\n",
    "\n",
    "train_dataset, val_dataset = random_split(full_dataset, [TRAIN_SIZE, VAL_SIZE])\n",
    "\n",
    "test_dataset = PeopleDataset(data=TEST_PATH, masks=None, img_transforms=transform_data, mask_transforms=None)\n",
    "\n",
    "\n",
    "def get_data_loaders(batch_size):\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=NUM_WORKERS\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "c9ZHzYRCp3ir"
   },
   "outputs": [],
   "source": [
    "# Obtenemos los dataloaders\n",
    "train_loader, val_loader, test_loader = get_data_loaders(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NNOFFuxWXi_V",
    "outputId": "dffa8d7d-2d37-4da6-c042-85968018bb05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([3, 224, 224]) torch.Size([224, 224])\n",
      "torch.Size([32, 3, 224, 224]) torch.Size([32, 224, 224])\n",
      "tensor(0, dtype=torch.uint8) tensor(255, dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "# Testeamos el dataloader\n",
    "# obteniendo un minibatch\n",
    "imgs, masks = next(iter(train_loader))\n",
    "for i in range(len(imgs)):\n",
    "  print(imgs[i].shape, masks[i].shape)\n",
    "print(imgs.shape, masks.shape)\n",
    "print(imgs.min(), imgs.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "ZkwiJr87n2-_"
   },
   "outputs": [],
   "source": [
    "def plot_mini_batch(imgs, masks, show_mask=True):\n",
    "  '''\n",
    "  Función para mostrar un mini batch de imágenes y máscaras\n",
    "  '''\n",
    "  plt.figure(figsize=(20,10))\n",
    "  for i in range(BATCH_SIZE):\n",
    "    plt.subplot(4, 8, i+1)\n",
    "    # Permutamos al tratarse de un tensor\n",
    "    img=imgs[i,...].permute(1,2,0).to(DEVICE).cpu().numpy()\n",
    "    mask=masks[i,...].to(DEVICE).cpu().numpy()\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    # Incluimos la máscara\n",
    "    if show_mask:\n",
    "      plt.imshow(mask[0], alpha=0.6, cmap='gray',vmin=0,vmax=1)\n",
    "    plt.axis('off')\n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 753
    },
    "id": "c0_7QKi3Vc6T",
    "outputId": "2e38385d-b858-4f49-973d-55775ab6a4a0"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Mostramos un mini batch de las imágenes\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# plot_mini_batch(imgs, masks, True)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# show_tensor_image(img[BATCH_SIZE-1], title=\"Imágen\", vmin=0, vmax=255)\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# show_tensor_images(imgs, title=\"Imágen\", vmin=0, vmax=255)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mshow_tensor_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEjemplos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Mostramos a continuación que cualquiera de las capas\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# de la máscara, contienen el mismo valor\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# plt.imshow(masks[BATCH_SIZE-1][2], cmap='gray', vmin=0, vmax=1)\u001b[39;00m\n",
      "File \u001b[0;32m~/Facultad/2024/tallerdl/obligatoriotallerdl/utils.py:299\u001b[0m, in \u001b[0;36mshow_tensor_images\u001b[0;34m(tensors, titles, figsize, vmin, vmax)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Assume RGB\u001b[39;00m\n\u001b[1;32m    298\u001b[0m     ax\u001b[38;5;241m.\u001b[39mimshow(tensor\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m), vmin\u001b[38;5;241m=\u001b[39mvmin, vmax\u001b[38;5;241m=\u001b[39mvmax)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m titles \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mtitles\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    300\u001b[0m     ax\u001b[38;5;241m.\u001b[39mset_title(titles[i])\n\u001b[1;32m    301\u001b[0m ax\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: string index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostramos un mini batch de las imágenes\n",
    "# plot_mini_batch(imgs, masks, True)\n",
    "\n",
    "# show_tensor_image(img[BATCH_SIZE-1], title=\"Imágen\", vmin=0, vmax=255)\n",
    "\n",
    "# show_tensor_images(imgs, title=\"Imágen\", vmin=0, vmax=255)\n",
    "show_tensor_images(imgs, titles=\"Ejemplos\", figsize=(15, 5), vmin=0, vmax=255)\n",
    "# Mostramos a continuación que cualquiera de las capas\n",
    "# de la máscara, contienen el mismo valor\n",
    "# plt.imshow(masks[BATCH_SIZE-1][2], cmap='gray', vmin=0, vmax=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vDlCkTOEUe14"
   },
   "source": [
    "# Modelo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcL2_-3nw6HE"
   },
   "source": [
    "Dada la estructura de la U-Net, y la repetición de los bloques de\n",
    "convolución tanto en la sección de down-sampling como en la de\n",
    "up-sampling, crearemos clases con la estructura de la\n",
    "convolución. De esta forma, simplificaremos el\n",
    "código parametrizando dichas convoluciones\n",
    "de acuerdo a la etapa de la red en la\n",
    "que nos encontremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sETT_-neUnG_"
   },
   "outputs": [],
   "source": [
    "# class Conv_3x3_block(nn.Module):\n",
    "#   def __init__(self, channels_in, channels_out):\n",
    "#     super(Conv_3x3_block, self).__init__()\n",
    "#     # Utilizaremos padding para que las imágenes no se modifiquen\n",
    "#     self.conv1 = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=1, padding=1)\n",
    "#   def forward(self, x):\n",
    "#     return self.conv1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IAqJAOxY0FSP"
   },
   "outputs": [],
   "source": [
    "# class Double_Conv(nn.Module):\n",
    "#   def __init__(self, channels_in, channels_out):\n",
    "#     super(Double_Conv, self).__init__()\n",
    "#     self.double_conv = nn.Sequential(\n",
    "#         Conv_3x3_block(channels_in, channels_out),\n",
    "#         # Vamos a normalizar los datos para facilitar\n",
    "#         # el entrenamiento.\n",
    "#         nn.BatchNorm2d(channels_out),\n",
    "#         nn.ReLU(),\n",
    "#         Conv_3x3_block(channels_out, channels_out),\n",
    "#         nn.BatchNorm2d(channels_out),\n",
    "#         nn.ReLU()\n",
    "#     )\n",
    "#   def forward(self, x):\n",
    "#     return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9Y4EO6q2gEQ"
   },
   "outputs": [],
   "source": [
    "# # Vamos a comenzar con la primera sección de la U-Net\n",
    "# class Down_conv_encoder(nn.Module):\n",
    "#   def __init__(self,  channels_in, channels_out):\n",
    "#     super(Down_conv_encoder, self).__init__()\n",
    "#     self.down_sampling = nn.Sequential(\n",
    "#                         nn.MaxPool2d(2,2),\n",
    "#                         Double_Conv(channels_in, channels_out)\n",
    "#                       )\n",
    "#   def forward(self, x):\n",
    "#     return self.down_sampling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81ecA_Np3hJN"
   },
   "outputs": [],
   "source": [
    "# # Ahora continuamos con la sección del up-sampling de la U-Net\n",
    "# class Up_conv_decoder(nn.Module):\n",
    "#   def __init__(self, channels_in, channels_out):\n",
    "#     super(Up_conv_decoder, self).__init__()\n",
    "#     self.up_sampling = nn.Sequential(\n",
    "#                         #nn.Upsample(scale_factor=2, mode='bicubic'),\n",
    "#                         nn.ConvTranspose2d(channels_in, channels_out, kernel_size=2, stride=2),\n",
    "#                         nn.Conv2d(channels_in, channels_in//2, kernel_size=1, stride=1)\n",
    "#                         )\n",
    "#     self.decoder=Double_Conv(channels_in, channels_out)\n",
    "\n",
    "#     # x2: representa el skip connection\n",
    "#     #     proveniente de la sección la\n",
    "#     #     etapa de down sampling\n",
    "\n",
    "#   def forward(self, x1, x2):\n",
    "#     x1 = self.up_sampling(x1)\n",
    "#     # Concatenamos en la dimensión de los canales\n",
    "#     # La dim=0 corresponde con la dimensión\n",
    "#     # del batch.\n",
    "#     x = torch.cat([x2, x1], dim=1)\n",
    "#     return self.decoder(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SL75-T87V7xi"
   },
   "source": [
    "Ahora, vamos a ensamblar los diferentes componentes para finalmente\n",
    "armar la U-Net de acuerdo al paper original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "znhHacA0Am_R"
   },
   "outputs": [],
   "source": [
    "# class UNET(nn.Module):\n",
    "#   def __init__(self, channels_in, channels, num_classes):\n",
    "#     super(UNET, self).__init__()\n",
    "#     self.encoder_1 = Double_Conv(channels_in, channels)\n",
    "#     self.encoder_2 = Down_conv_encoder(channels, 2*channels)\n",
    "#     self.encoder_3 = Down_conv_encoder(2*channels, 4*channels)\n",
    "#     self.encoder_4 = Down_conv_encoder(4*channels, 8*channels)\n",
    "#     self.encoder_5 = Down_conv_encoder(8*channels, 16*channels)\n",
    "\n",
    "#     self.decoder_1 = Up_conv_decoder(16*channels, 8*channels)\n",
    "#     self.decoder_2 = Up_conv_decoder(8*channels, 4*channels)\n",
    "#     self.decoder_3 = Up_conv_decoder(4*channels, 2*channels)\n",
    "#     self.decoder_4 = Up_conv_decoder(2*channels, channels)\n",
    "\n",
    "#     self.last_conv = nn.Conv2d(channels, num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "#   def forward(self, x):\n",
    "#     x1 = self.encoder_1(x)\n",
    "#     x2 = self.encoder_2(x1)\n",
    "#     x3 = self.encoder_3(x2)\n",
    "#     x4 = self.encoder_4(x3)\n",
    "\n",
    "#     x5 = self.encoder_5(x4)\n",
    "\n",
    "#     u1 = self.decoder_1(x5, x4)\n",
    "#     u2 = self.decoder_2(u1, x3)\n",
    "#     u3 = self.decoder_3(u2, x2)\n",
    "#     u4 = self.decoder_4(u3, x1)\n",
    "\n",
    "#     return self.last_conv(u4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "-gSjF2zCWv1F"
   },
   "outputs": [],
   "source": [
    "class Conv_3_k(nn.Module):\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(channels_in, channels_out, kernel_size=3, stride=1, padding=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv1(x)\n",
    "\n",
    "class Double_Conv(nn.Module):\n",
    "    '''\n",
    "    Double convolution block for U-Net\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "                           Conv_3_k(channels_in, channels_out),\n",
    "                           nn.BatchNorm2d(channels_out),\n",
    "                           nn.ReLU(),\n",
    "\n",
    "                           Conv_3_k(channels_out, channels_out),\n",
    "                           nn.BatchNorm2d(channels_out),\n",
    "                           nn.ReLU(),\n",
    "                            )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down_Conv(nn.Module):\n",
    "    '''\n",
    "    Down convolution part\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        Double_Conv(channels_in, channels_out)\n",
    "                        )\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Up_Conv(nn.Module):\n",
    "    '''\n",
    "    Up convolution part\n",
    "    '''\n",
    "    def __init__(self,channels_in, channels_out):\n",
    "        super().__init__()\n",
    "        self.upsample_layer = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='bicubic'),\n",
    "                        nn.Conv2d(channels_in, channels_in//2, kernel_size=1, stride=1)\n",
    "                        )\n",
    "        self.decoder = Double_Conv(channels_in, channels_out)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        '''\n",
    "        x1 - upsampled volume\n",
    "        x2 - volume from down sample to concatenate\n",
    "        '''\n",
    "        x1 = self.upsample_layer(x1)\n",
    "        x = torch.cat([x2, x1],dim=1)\n",
    "        return self.decoder(x)\n",
    "\n",
    "class UNET(nn.Module):\n",
    "    '''\n",
    "    UNET model\n",
    "    '''\n",
    "    def __init__(self, channels_in, channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.first_conv = Double_Conv(channels_in, channels) #64, 224, 224\n",
    "        self.down_conv1 = Down_Conv(channels, 2*channels) # 128, 112, 112\n",
    "        self.down_conv2 = Down_Conv(2*channels, 4*channels) # 256, 56, 56\n",
    "        self.down_conv3 = Down_Conv(4*channels, 8*channels) # 512, 28, 28\n",
    "\n",
    "        self.middle_conv = Down_Conv(8*channels, 16*channels) # 1024, 14, 14\n",
    "\n",
    "        self.up_conv1 = Up_Conv(16*channels, 8*channels)\n",
    "        self.up_conv2 = Up_Conv(8*channels, 4*channels)\n",
    "        self.up_conv3 = Up_Conv(4*channels, 2*channels)\n",
    "        self.up_conv4 = Up_Conv(2*channels, channels)\n",
    "\n",
    "        self.last_conv = nn.Conv2d(channels, num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.first_conv(x)\n",
    "        x2 = self.down_conv1(x1)\n",
    "        x3 = self.down_conv2(x2)\n",
    "        x4 = self.down_conv3(x3)\n",
    "\n",
    "        x5 = self.middle_conv(x4)\n",
    "\n",
    "        u1 = self.up_conv1(x5, x4)\n",
    "        u2 = self.up_conv2(u1, x3)\n",
    "        u3 = self.up_conv3(u2, x2)\n",
    "        u4 = self.up_conv4(u3, x1)\n",
    "\n",
    "        return self.last_conv(u4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPmCKtrbZXml",
    "outputId": "99d1b311-7ac5-45c4-c958-e0806de99f00"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "UNET                                          [32, 2, 224, 224]         --\n",
       "├─Double_Conv: 1-1                            [32, 64, 224, 224]        --\n",
       "│    └─Sequential: 2-1                        [32, 64, 224, 224]        --\n",
       "│    │    └─Conv_3_k: 3-1                     [32, 64, 224, 224]        1,792\n",
       "│    │    └─BatchNorm2d: 3-2                  [32, 64, 224, 224]        128\n",
       "│    │    └─ReLU: 3-3                         [32, 64, 224, 224]        --\n",
       "│    │    └─Conv_3_k: 3-4                     [32, 64, 224, 224]        36,928\n",
       "│    │    └─BatchNorm2d: 3-5                  [32, 64, 224, 224]        128\n",
       "│    │    └─ReLU: 3-6                         [32, 64, 224, 224]        --\n",
       "├─Down_Conv: 1-2                              [32, 128, 112, 112]       --\n",
       "│    └─Sequential: 2-2                        [32, 128, 112, 112]       --\n",
       "│    │    └─MaxPool2d: 3-7                    [32, 64, 112, 112]        --\n",
       "│    │    └─Double_Conv: 3-8                  [32, 128, 112, 112]       221,952\n",
       "├─Down_Conv: 1-3                              [32, 256, 56, 56]         --\n",
       "│    └─Sequential: 2-3                        [32, 256, 56, 56]         --\n",
       "│    │    └─MaxPool2d: 3-9                    [32, 128, 56, 56]         --\n",
       "│    │    └─Double_Conv: 3-10                 [32, 256, 56, 56]         886,272\n",
       "├─Down_Conv: 1-4                              [32, 512, 28, 28]         --\n",
       "│    └─Sequential: 2-4                        [32, 512, 28, 28]         --\n",
       "│    │    └─MaxPool2d: 3-11                   [32, 256, 28, 28]         --\n",
       "│    │    └─Double_Conv: 3-12                 [32, 512, 28, 28]         3,542,016\n",
       "├─Down_Conv: 1-5                              [32, 1024, 14, 14]        --\n",
       "│    └─Sequential: 2-5                        [32, 1024, 14, 14]        --\n",
       "│    │    └─MaxPool2d: 3-13                   [32, 512, 14, 14]         --\n",
       "│    │    └─Double_Conv: 3-14                 [32, 1024, 14, 14]        14,161,920\n",
       "├─Up_Conv: 1-6                                [32, 512, 28, 28]         --\n",
       "│    └─Sequential: 2-6                        [32, 512, 28, 28]         --\n",
       "│    │    └─Upsample: 3-15                    [32, 1024, 28, 28]        --\n",
       "│    │    └─Conv2d: 3-16                      [32, 512, 28, 28]         524,800\n",
       "│    └─Double_Conv: 2-7                       [32, 512, 28, 28]         --\n",
       "│    │    └─Sequential: 3-17                  [32, 512, 28, 28]         7,080,960\n",
       "├─Up_Conv: 1-7                                [32, 256, 56, 56]         --\n",
       "│    └─Sequential: 2-8                        [32, 256, 56, 56]         --\n",
       "│    │    └─Upsample: 3-18                    [32, 512, 56, 56]         --\n",
       "│    │    └─Conv2d: 3-19                      [32, 256, 56, 56]         131,328\n",
       "│    └─Double_Conv: 2-9                       [32, 256, 56, 56]         --\n",
       "│    │    └─Sequential: 3-20                  [32, 256, 56, 56]         1,771,008\n",
       "├─Up_Conv: 1-8                                [32, 128, 112, 112]       --\n",
       "│    └─Sequential: 2-10                       [32, 128, 112, 112]       --\n",
       "│    │    └─Upsample: 3-21                    [32, 256, 112, 112]       --\n",
       "│    │    └─Conv2d: 3-22                      [32, 128, 112, 112]       32,896\n",
       "│    └─Double_Conv: 2-11                      [32, 128, 112, 112]       --\n",
       "│    │    └─Sequential: 3-23                  [32, 128, 112, 112]       443,136\n",
       "├─Up_Conv: 1-9                                [32, 64, 224, 224]        --\n",
       "│    └─Sequential: 2-12                       [32, 64, 224, 224]        --\n",
       "│    │    └─Upsample: 3-24                    [32, 128, 224, 224]       --\n",
       "│    │    └─Conv2d: 3-25                      [32, 64, 224, 224]        8,256\n",
       "│    └─Double_Conv: 2-13                      [32, 64, 224, 224]        --\n",
       "│    │    └─Sequential: 3-26                  [32, 64, 224, 224]        110,976\n",
       "├─Conv2d: 1-10                                [32, 2, 224, 224]         130\n",
       "===============================================================================================\n",
       "Total params: 28,954,626\n",
       "Trainable params: 28,954,626\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 1.18\n",
       "===============================================================================================\n",
       "Input size (MB): 19.27\n",
       "Forward/backward pass size (MB): 14103.87\n",
       "Params size (MB): 115.82\n",
       "Estimated Total Size (MB): 14238.96\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(UNET(3, 64, 2), input_size=(BATCH_SIZE, 3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pso29u7yZnZt"
   },
   "source": [
    "Como puede observarse en el resumen, el modelo y su arquitectura hacen computacionalmente pesado el proceso. De lo anterior, puede observarse\n",
    "que se requieren unos 14 GB de memoria RAM aproximadamente por cada\n",
    "\"forward\" de un batch. Esto podría tener implicancias en el entrenamiento\n",
    "ya que dados los recursos de hardware, es posible que se tengan que\n",
    "variar tanto el BATCH_SIZE, como el tamaño de las imágenes a procesar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "czP9VsleMPsA",
    "outputId": "c94084ea-0ea6-4f52-e09e-3c366364917b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "# Definimos una función de test, y observamos el shape\n",
    "# del modelo luego de la predicción\n",
    "def test():\n",
    "    x = torch.randn((32, 3, 224, 224))\n",
    "    model = UNET(3, 64, 2)\n",
    "    return model(x)\n",
    "\n",
    "preds = test()\n",
    "print(preds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TqOT9izaWmV"
   },
   "source": [
    "# Entrenamiento\n",
    "\n",
    "Probemos inicialmente un entrenamiento del modelo, sin realizar ninguna manipulación de las imágenes más allá de modificar su tamaño a 224x224 para mantener un tamaño reducido y no sobrecargar la memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "ndYMYCjSh8O2"
   },
   "outputs": [],
   "source": [
    "def accuracy(model, loader):\n",
    "    correct = 0\n",
    "    intersection = 0\n",
    "    denom = 0\n",
    "    union = 0\n",
    "    total = 0\n",
    "    cost = 0.\n",
    "    model = model.to(device=device)\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=DEVICE, dtype = torch.float32)\n",
    "            y = y.to(device=DEVICE, dtype = torch.long).squeeze(1)\n",
    "            scores = model(x)\n",
    "            cost += (F.cross_entropy(scores, y)).item()\n",
    "            # standard accuracy not optimal\n",
    "            preds = torch.argmax(scores, dim=1)\n",
    "            correct += (preds == y).sum()\n",
    "            total += torch.numel(preds)\n",
    "            #dice coefficient\n",
    "            intersection += (preds*y).sum()\n",
    "            denom += (preds + y).sum()\n",
    "            dice = 2*intersection/(denom + 1e-8)\n",
    "            #intersection over union\n",
    "            union += (preds + y - preds*y).sum()\n",
    "            iou = (intersection)/(union + 1e-8)\n",
    "\n",
    "        return cost/len(loader), float(correct)/total, dice, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "zxOBa-wOhv3a"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(model, optimiser, scheduler = None, epochs = 100, store_every = 25):\n",
    "    model = model.to(device=DEVICE)\n",
    "    for epoch in range(epochs):\n",
    "        train_correct_num = 0\n",
    "        train_total = 0\n",
    "        train_cost_acum = 0.\n",
    "        for mb, (x, y) in enumerate(train_loader, start=1):\n",
    "            model.train()\n",
    "            x = x.to(device=DEVICE, dtype=torch.float32)\n",
    "            y = y.to(device=DEVICE, dtype=torch.long).squeeze(1)\n",
    "            scores = model(x)\n",
    "            cost = F.cross_entropy(input=scores, target=y)\n",
    "            optimiser.zero_grad()\n",
    "            cost.backward()\n",
    "            optimiser.step()\n",
    "\n",
    "            if scheduler:\n",
    "                scheduler.step()\n",
    "\n",
    "            train_predictions = torch.argmax(scores, dim=1)\n",
    "            train_correct_num += (train_predictions == y).sum()\n",
    "            train_total += torch.numel(train_predictions)\n",
    "            train_cost_acum += cost.item()\n",
    "            if mb%store_every == 0:\n",
    "                val_cost, val_acc, dice, iou = accuracy(model, val_loader)\n",
    "                train_acc = float(train_correct_num)/train_total\n",
    "                train_cost_every = float(train_cost_acum)/mb\n",
    "                print(f'epoch: {epoch}, mb: {mb}, train cost: {train_cost_every:.4f}, val cost: {val_cost:.4f},'\n",
    "                      f'train acc: {train_acc:.4f}, val acc: {val_acc:.4f},'\n",
    "                      f'dice: {dice:.4f}, iou: {iou:.4f}')\n",
    "                    # Save data\n",
    "                    #train_acc_history.append(train_acc)\n",
    "                    #train_cost_history.append(train_cost_every)\n",
    "        #train_acc = float(train_correct_num)/train_total\n",
    "        #train_cost_every = float(train_cost_acum)/len(train_loader)\n",
    "        # return train_acc_history ... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "Qb7uZKuni1A7"
   },
   "outputs": [],
   "source": [
    "def find_lr(model, optimiser, start_val = 1e-6, end_val = 1, beta = 0.99, loader = train_loader):\n",
    "    n = len(loader) - 1\n",
    "    factor = (end_val / start_val)**(1/n)\n",
    "    lr = start_val\n",
    "    optimiser.param_groups[0]['lr'] = lr #this allows you to update the learning rate\n",
    "    avg_loss, loss, acc = 0., 0., 0.\n",
    "    lowest_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    accuracies = []\n",
    "    model = model.to(device=DEVICE)\n",
    "    for i, (x, y) in enumerate(loader, start=1):\n",
    "        x = x.to(device = DEVICE, dtype = torch.float32)\n",
    "        y = y.to(device = DEVICE, dtype = torch.long).squeeze(1)\n",
    "        optimiser.zero_grad()\n",
    "        scores = model(x)\n",
    "        cost = F.cross_entropy(input=scores, target=y)\n",
    "        loss = beta*loss + (1-beta)*cost.item()\n",
    "        #bias correction\n",
    "        avg_loss = loss/(1 - beta**i)\n",
    "\n",
    "        preds = torch.argmax(scores, dim=1)\n",
    "        acc_ = (preds == y).sum()/torch.numel(scores)\n",
    "#         acc = beta*acc + (1-beta)*acc_.item()\n",
    "#         avg_acc = acc/(1 - beta**i)\n",
    "        #if loss is massive stop\n",
    "        if i > 1 and avg_loss > 4 * lowest_loss:\n",
    "            print(f'from here{i, cost.item()}')\n",
    "            return log_lrs, losses, accuracies\n",
    "        if avg_loss < lowest_loss or i == 1:\n",
    "            lowest_loss = avg_loss\n",
    "\n",
    "        accuracies.append(acc_.item())\n",
    "#         accuracies.append(avg_acc)\n",
    "        losses.append(avg_loss)\n",
    "        log_lrs.append(lr)\n",
    "        #step\n",
    "        cost.backward()\n",
    "        optimiser.step()\n",
    "        #update lr\n",
    "        print(f'cost:{cost.item():.4f}, lr: {lr:.4f}, acc: {acc_.item():.4f}')\n",
    "        lr *= factor\n",
    "        optimiser.param_groups[0]['lr'] = lr\n",
    "\n",
    "    return log_lrs, losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4Sbw6pQiwSv",
    "outputId": "008effec-ed9e-4190-de3b-69376fe15a25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:0.7389, lr: 0.0000, acc: 0.2478\n",
      "cost:0.7493, lr: 0.0001, acc: 0.2330\n",
      "cost:0.7018, lr: 0.0032, acc: 0.2847\n",
      "cost:0.6986, lr: 0.1778, acc: 0.2762\n",
      "cost:0.7225, lr: 10.0000, acc: 0.2588\n"
     ]
    }
   ],
   "source": [
    "# define the model and look for learning rate\n",
    "torch.manual_seed(42)\n",
    "model = UNET(3, 4, 2)\n",
    "optimiser_unet = torch.optim.SGD(model.parameters(),\n",
    "                                 lr=0.01, momentum=0.95,\n",
    "                                 weight_decay=1e-4)\n",
    "\n",
    "lg_lr, losses, accuracies = find_lr(model, optimiser_unet, start_val=1e-6, end_val=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 210
    },
    "id": "XZ2cZFVMajtW",
    "outputId": "21b74dca-f53d-4cfb-8793-7f4ee1f96967"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (unsigned char) and bias type (float) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m UNET(\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_unet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCrossEntropyLoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprint_log\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Facultad/2024/tallerdl/obligatoriotallerdl/utils.py:200\u001b[0m, in \u001b[0;36mtrain_unet\u001b[0;34m(model, optimizer, criterion, train_loader, val_loader, device, do_early_stopping, patience, epochs, log_fn, log_every)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_unet\u001b[39m(\n\u001b[1;32m    173\u001b[0m     model,\n\u001b[1;32m    174\u001b[0m     optimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m     log_every\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    182\u001b[0m ):\n\u001b[1;32m    183\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03m    Entrena el modelo utilizando el optimizador y la función de pérdida proporcionados.\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \n\u001b[1;32m    186\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;124;03m        model (torch.nn.Module): El modelo que se va a entrenar.\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;124;03m        optimizer (torch.optim.Optimizer): El optimizador que se utilizará para actualizar los pesos del modelo.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;124;03m        criterion (torch.nn.Module): La función de pérdida que se utilizará para calcular la pérdida.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m        train_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de entrenamiento.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m        val_loader (torch.utils.data.DataLoader): DataLoader que proporciona los datos de validación.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m        device (str): El dispositivo donde se ejecutará el entrenamiento.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m        epochs (int): Número de épocas de entrenamiento (default: 10).\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m        log_fn (function): Función que se llamará después de cada log_every épocas con los argumentos (epoch, train_loss, val_loss) (default: None).\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        log_every (int): Número de épocas entre cada llamada a log_fn (default: 1).\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \n\u001b[1;32m    197\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        Tuple[List[float], List[float]]: Una tupla con dos listas, la primera con el error de entrenamiento de cada época y la segunda con el error de validación de cada época.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     epoch_train_errors \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# colectamos el error de traing para posterior analisis\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     epoch_val_errors \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# colectamos el error de validacion para posterior analisis\u001b[39;00m\n",
      "File \u001b[0;32m~/Facultad/2024/tallerdl/obligatoriotallerdl/utils.py:28\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, criterion, data_loader, device)\u001b[0m\n\u001b[1;32m     26\u001b[0m         x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# movemos los datos al dispositivo\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# movemos los datos al dispositivo\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# forward pass\u001b[39;00m\n\u001b[1;32m     29\u001b[0m         total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(output, y)\u001b[38;5;241m.\u001b[39mitem()  \u001b[38;5;66;03m# acumulamos la perdida\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[63], line 81\u001b[0m, in \u001b[0;36mUNET.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 81\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_conv1(x1)\n\u001b[1;32m     83\u001b[0m     x3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown_conv2(x2)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[63], line 24\u001b[0m, in \u001b[0;36mDouble_Conv.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdouble_conv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[63], line 6\u001b[0m, in \u001b[0;36mConv_3_k.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/taller_dl/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (unsigned char) and bias type (float) should be the same"
     ]
    }
   ],
   "source": [
    "\n",
    "model = UNET(3,64, 2).to(DEVICE)\n",
    "\n",
    "train_unet(\n",
    "    model=model,\n",
    "    optimizer=optim.SGD(model.parameters(), lr=0.01),\n",
    "    criterion=nn.CrossEntropyLoss().to(DEVICE),\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    device=DEVICE,\n",
    "    patience=5,\n",
    "    epochs=10,\n",
    "    log_fn=print_log,\n",
    "    log_every=1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "taller_dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
